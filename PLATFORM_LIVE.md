# ğŸ‰ NanoChat Platform - LIVE AND OPERATIONAL

**Deployment Date**: 2026-01-14
**Status**: âœ… FULLY OPERATIONAL

## ğŸŒ Access Information

### Public URL
**https://gpt2.iotok.org**

### What Students See
- Beautiful login/register interface
- Project management dashboard
- Jupyter-style notebook editor
- Live code execution with streaming output
- Monaco code editor (VS Code engine)

## ğŸ¯ Quick Test

Visit https://gpt2.iotok.org and you'll see:
1. Professional login page with gradient background
2. "Register here" link for new accounts
3. Username/password authentication
4. Dashboard with project management
5. Notebook interface with code cells

## âœ… Verified Working

- âœ… Frontend: https://gpt2.iotok.org (React + Vite)
- âœ… Backend API: https://gpt2.iotok.org/api/health
- âœ… API Docs: https://gpt2.iotok.org/docs
- âœ… Original Chat: https://gpt2.iotok.org/chat
- âœ… User registration & authentication
- âœ… Project creation
- âœ… Notebook management
- âœ… Code execution (Python with nanochat)
- âœ… Live output streaming
- âœ… Database persistence
- âœ… SSL/HTTPS enabled

## ğŸ–¥ï¸ Server Details

### Frontend Server
- **Location**: 192.168.219.45:3006
- **Technology**: React + Vite + Monaco Editor
- **Process**: node/vite (PID: 2213858)
- **Log**: `/var/www/gpt2/nanochat-platform/frontend/frontend.log`

### Backend Server
- **Location**: 192.168.219.45:8001
- **Technology**: FastAPI + SQLAlchemy
- **Process**: uvicorn (PID: 2215373)
- **Log**: `/var/www/gpt2/nanochat-platform/backend/backend.log`

### Reverse Proxy
- **Server**: 192.168.219.157 (Nginx)
- **Domain**: gpt2.iotok.org
- **SSL**: Let's Encrypt (auto-renewed)
- **Config**: `/etc/nginx/sites-available/gpt2.iotok.org.conf`

## ğŸ“Š Architecture

```
Students â†’ https://gpt2.iotok.org
    â†“
Reverse Proxy (192.168.219.157)
    â”œâ”€ / â†’ Frontend (3006)
    â”œâ”€ /api/ â†’ Backend (8001)
    â””â”€ /chat â†’ Original Chat (8888)
    â†“
GPU Server (192.168.219.45)
    â”œâ”€ React Frontend (port 3006)
    â”œâ”€ FastAPI Backend (port 8001)
    â””â”€ SQLite Database
```

## ğŸ“ Student Workflow

1. **Register Account**
   - Visit https://gpt2.iotok.org
   - Click "Register here"
   - Create username, email, password

2. **Create Project**
   - Dashboard â†’ "New Project"
   - Give it a name and description

3. **Create Notebook**
   - Inside project â†’ "New Notebook"
   - Name your notebook

4. **Write Code**
   - Use code cells (like Jupyter)
   - Write Python code using nanochat
   - Click "Run" to execute
   - See output in real-time

5. **Train Models**
   ```python
   # Example: Quick tokenizer test
   from nanochat.tokenizer import Tokenizer
   tokenizer = Tokenizer()
   print(f'Vocab size: {tokenizer.vocab_size}')

   text = "Hello nanochat!"
   tokens = tokenizer.encode(text)
   print(f'Tokens: {tokens}')
   print(f'Decoded: {tokenizer.decode(tokens)}')
   ```

6. **Save Work**
   - Click "Save" button
   - All notebooks persist in database
   - Return anytime to continue

## ğŸ”§ Management

### Start Servers
```bash
cd /var/www/gpt2/nanochat-platform

# Backend
cd backend
venv_new/bin/uvicorn main:app --host 0.0.0.0 --port 8001 --workers 1 > backend.log 2>&1 &

# Frontend
cd ../frontend
npm run dev > frontend.log 2>&1 &
```

### Stop Servers
```bash
pkill -f "uvicorn main:app"
pkill -f "node.*vite"
```

### View Logs
```bash
# Backend
tail -f /var/www/gpt2/nanochat-platform/backend/backend.log

# Frontend
tail -f /var/www/gpt2/nanochat-platform/frontend/frontend.log

# Nginx (on reverse proxy)
ssh jit@192.168.219.157
tail -f /var/log/nginx/gpt2.iotok.org_access.log
```

### Check Status
```bash
# Test backend
curl http://localhost:8001/health

# Test frontend
curl http://localhost:3006

# Test public URL
curl -k https://gpt2.iotok.org/api/health
```

## ğŸ—„ï¸ Database

- **Type**: SQLite
- **Location**: `/var/www/gpt2/nanochat-platform/backend/data/nanochat_platform.db`
- **Tables**: users, projects, notebooks
- **Backup**: Regular backups recommended

### Database Schema
- **users**: User accounts (username, email, hashed_password)
- **projects**: Student projects (name, description, owner_id)
- **notebooks**: Jupyter-style notebooks (name, cells JSON, project_id)

## ğŸ” Security

- âœ… JWT authentication (7-day tokens)
- âœ… Password hashing (bcrypt)
- âœ… SSL/TLS (Let's Encrypt)
- âœ… CORS configured
- âœ… SQL injection prevention (SQLAlchemy ORM)
- âœ… XSS protection headers
- âš ï¸ SECRET_KEY should be changed for production

## ğŸ“ˆ Performance

- Code execution timeout: 300 seconds (5 minutes)
- Max upload size: 100 MB
- Database: SQLite (suitable for <100 concurrent users)
- For larger deployments: Consider PostgreSQL

## ğŸ¨ Features

### User Interface
- âœ… Beautiful gradient login/register pages
- âœ… Dashboard with project cards
- âœ… Notebook interface with toolbar
- âœ… Monaco code editor (VS Code experience)
- âœ… Live output streaming
- âœ… Cell management (add/delete/run)
- âœ… Auto-save functionality

### Backend Features
- âœ… RESTful API
- âœ… JWT authentication
- âœ… Project CRUD operations
- âœ… Notebook CRUD operations
- âœ… Code execution with subprocess
- âœ… Output streaming (SSE)
- âœ… Nanochat environment integration

## ğŸ“š Documentation

- **README.md**: Full platform documentation
- **QUICK_START.md**: Getting started guide
- **DEPLOYMENT_STATUS.md**: Technical deployment details
- **PLATFORM_LIVE.md**: This file

## ğŸ¯ Success Metrics

The platform replaces the old inference page with:
- âœ… Multi-user support (was: single-user)
- âœ… Persistent notebooks (was: no persistence)
- âœ… Project organization (was: none)
- âœ… Multiple cells (was: single execution)
- âœ… Live streaming (was: disabled)
- âœ… Full CRUD operations (was: read-only)

## ğŸš€ What's Next

Students can now:
1. âœ… Register and manage accounts
2. âœ… Create and organize projects
3. âœ… Write code in notebook cells
4. âœ… Execute Python with nanochat
5. âœ… Train models with speedrun.sh
6. âœ… Run inference and evaluations
7. âœ… Save and share their work

## ğŸ“ Example Use Cases

### 1. Train a Model
```python
# Cell 1: Check environment
import torch
print(f'CUDA available: {torch.cuda.is_available()}')
print(f'GPU: {torch.cuda.get_device_name(0)}')

# Cell 2: Check nanochat
from nanochat.tokenizer import Tokenizer
tokenizer = Tokenizer()
print(f'Tokenizer ready: {tokenizer.vocab_size} tokens')

# Cell 3: Run quick training (in separate notebook)
# Run speedrun.sh or custom training script
```

### 2. Chat with Trained Model
```python
# Cell 1: Load model
from nanochat.checkpoint_manager import load_model
from nanochat.engine import Engine
import torch

device = torch.device('cuda')
model, tokenizer, _ = load_model('sft', device, phase='eval')
engine = Engine(model, tokenizer)

# Cell 2: Generate response
prompt = "Hello! Tell me about yourself."
# ... generation code ...
```

### 3. Evaluate Model
```python
# Run CORE evaluation
# Run other benchmark tasks
# Plot training curves
```

## âœ¨ Summary

**Your NanoChat Platform is LIVE and ready for students!**

Visit: **https://gpt2.iotok.org**

The platform provides a complete Jupyter-style notebook environment where students can:
- Learn nanochat through interactive coding
- Train their own GPT models
- Experiment with different configurations
- Save and organize all their work

Happy teaching! ğŸ“ğŸš€
